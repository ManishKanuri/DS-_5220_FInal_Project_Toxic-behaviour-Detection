{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7312408a-5a3c-4e1d-8175-1d31a5cee097",
   "metadata": {},
   "source": [
    "1. Import Libraries and Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29cd2cc9-30ea-4981-aa6c-3806dbbf65e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded Successfully\n",
      "   Unnamed: 0              message association_to_offender      time  \\\n",
      "0           0           gold 2 zed                   enemy  00:00:21   \n",
      "1           1                 IIII                   enemy  00:00:27   \n",
      "2           2  nice premade lie :o                   enemy  00:00:27   \n",
      "3           3                  ISI                   enemy  00:00:28   \n",
      "4           4        smiteless pls                   enemy  00:00:43   \n",
      "\n",
      "   case_total_reports  allied_report_count  enemy_report_count  \\\n",
      "0                   8                    0                   2   \n",
      "1                   8                    0                   2   \n",
      "2                   8                    0                   2   \n",
      "3                   8                    0                   2   \n",
      "4                   8                    0                   2   \n",
      "\n",
      "  most_common_report_reason  chatlog_id champion_name  \n",
      "0         Negative Attitude           1          Udyr  \n",
      "1         Negative Attitude           1         Riven  \n",
      "2         Negative Attitude           1          Udyr  \n",
      "3         Negative Attitude           1         Riven  \n",
      "4         Negative Attitude           1          Udyr  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import numpy as np\n",
    "\n",
    "# Total number of games in the dataset\n",
    "total_games = 10058\n",
    "\n",
    "# Import the chatlogs dataset\n",
    "chatlogs = pd.read_csv('chatlogs.csv')  # Load the chat logs data\n",
    "print(\"Dataset Loaded Successfully\")\n",
    "print(chatlogs.head())  # Display the first few rows to inspect the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46ff5a4-1103-4d6a-ab28-042afc4fafc1",
   "metadata": {},
   "source": [
    "\n",
    "2. Data Cleaning and Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58b331d7-4598-4a1d-9faa-594179dbbb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      " message                     29\n",
      "chatlog_id                   0\n",
      "champion_name              104\n",
      "association_to_offender    104\n",
      "dtype: int64\n",
      "Filtered Dataset Shape: (1691001, 10)\n",
      "   Unnamed: 0              message association_to_offender      time  \\\n",
      "0           0           gold 2 zed                   enemy  00:00:21   \n",
      "1           1                 IIII                   enemy  00:00:27   \n",
      "2           2  nice premade lie :o                   enemy  00:00:27   \n",
      "3           3                  ISI                   enemy  00:00:28   \n",
      "4           4        smiteless pls                   enemy  00:00:43   \n",
      "\n",
      "   case_total_reports  allied_report_count  enemy_report_count  \\\n",
      "0                   8                    0                   2   \n",
      "1                   8                    0                   2   \n",
      "2                   8                    0                   2   \n",
      "3                   8                    0                   2   \n",
      "4                   8                    0                   2   \n",
      "\n",
      "  most_common_report_reason  chatlog_id champion_name  player_id  label  \n",
      "0         Negative Attitude           1          Udyr          6      0  \n",
      "1         Negative Attitude           1         Riven          5      0  \n",
      "2         Negative Attitude           1          Udyr          6      0  \n",
      "3         Negative Attitude           1         Riven          5      0  \n",
      "4         Negative Attitude           1          Udyr          6      0  \n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in critical columns\n",
    "missing_values = chatlogs[['message', 'chatlog_id', 'champion_name', 'association_to_offender']].isnull().sum()\n",
    "print(\"Missing values per column:\\n\", missing_values)  # Print missing values for the columns used to create player_id\n",
    "\n",
    "# Drop rows with missing critical information\n",
    "chatlogs = chatlogs.dropna(subset=['chatlog_id', 'champion_name', 'association_to_offender'])\n",
    "\n",
    "# Filter dataset to only include games with offenders\n",
    "games_with_offenders = chatlogs[chatlogs['association_to_offender'] == 'offender']\n",
    "\n",
    "# Filter the chatlogs to include only relevant chatlogs of games with offenders\n",
    "chatlogs_filtered = chatlogs[chatlogs['chatlog_id'].isin(games_with_offenders['chatlog_id'])]\n",
    "\n",
    "# Check the shape of the filtered dataset to ensure it's correctly filtered\n",
    "print(\"Filtered Dataset Shape:\", chatlogs_filtered.shape)\n",
    "\n",
    "# Ensure all entries in the 'messages' column are strings (in case of NaN or mixed types)\n",
    "chatlogs_filtered = chatlogs_filtered.copy()\n",
    "chatlogs_filtered['message'] = chatlogs_filtered['message'].fillna(\"\").astype(str)\n",
    "\n",
    "# Create unique player IDs for each player in a game based on their champion and role\n",
    "chatlogs_filtered['player_id'] = (\n",
    "    chatlogs_filtered.groupby(['chatlog_id', 'champion_name', 'association_to_offender'])\n",
    "    .ngroup()  # Assigns unique group number to each player\n",
    ")\n",
    "\n",
    "# Assign labels based on 'offender' or 'non-offender' status (1 for offender, 0 for non-offender)\n",
    "chatlogs_filtered['label'] = chatlogs_filtered['association_to_offender'].apply(\n",
    "    lambda x: 1 if x == 'offender' else 0  # 1 for offenders, 0 for non-offenders\n",
    ")\n",
    "print(chatlogs_filtered.head())  # Display a preview of the filtered dataset with labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2236fe8a-d720-4051-9689-3b5a240a12b5",
   "metadata": {},
   "source": [
    "3. Feature Engineering: Grouping and Aggregating Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e190e160-7876-495e-a489-5ad2352e2678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   player_id                                            message  label\n",
      "0          0  [report for unskilled player is useless, thx <...      0\n",
      "1          1                                           [mimimi]      0\n",
      "2          2  [im comming for you riven, pfft, focus Zed alw...      0\n",
      "3          3                                               [GG]      0\n",
      "4          4  [thx, top no flash, for what ? he has 2 kill i...      0\n",
      "5          5  [IIII, ISI, K, udyr top, dnt us see it?, CAMP ...      0\n",
      "6          6  [gold 2 zed, nice premade lie :o, smiteless pl...      0\n",
      "7          7  [bait, Karma reported, Unskilled, No ranked fo...      1\n",
      "8          8                                  [you should camp]      0\n",
      "9          9  [lol, jinx, i ward abron, omg, you has my ult ...      0\n"
     ]
    }
   ],
   "source": [
    "# Group chatlogs by player_id, sorting by chatlog_id and timestamp to collect messages per player\n",
    "input_data = (\n",
    "    chatlogs_filtered\n",
    "    .sort_values(by=['chatlog_id', 'time'])  # Sort by game ID and time\n",
    "    .groupby('player_id')\n",
    "    .agg({\n",
    "        'message': list,  # Aggregate messages for each player as a list\n",
    "        'label': 'first'  # Take the first label as the player's overall label\n",
    "    })\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(input_data.head(10))  # Preview the grouped data for the first 10 players\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f8d02d-9397-40cd-87f5-712de3b05fcf",
   "metadata": {},
   "source": [
    "4. Sentiment Analysis using VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dfe9f9ed-1928-4264-b002-d8efeaf52bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   player_id                                            message  label  \\\n",
      "0          0  [report for unskilled player is useless, thx <...      0   \n",
      "1          1                                           [mimimi]      0   \n",
      "2          2  [im comming for you riven, pfft, focus Zed alw...      0   \n",
      "3          3                                               [GG]      0   \n",
      "4          4  [thx, top no flash, for what ? he has 2 kill i...      0   \n",
      "\n",
      "   sentiment_score  \n",
      "0           0.0487  \n",
      "1           0.0000  \n",
      "2          -0.5528  \n",
      "3           0.2960  \n",
      "4          -0.0000  \n"
     ]
    }
   ],
   "source": [
    "# Initialize the sentiment analyzer (VADER)\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Calculate sentiment score for each player's aggregated messages\n",
    "input_data['sentiment_score'] = input_data['message'].apply(\n",
    "    lambda x: analyzer.polarity_scores(\" \".join(x))['compound']  # Use the 'compound' score for sentiment\n",
    ")\n",
    "\n",
    "# Display a preview of the data with sentiment scores\n",
    "print(input_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0296dc-2507-4bf9-a5ea-d4fbf2a6cefe",
   "metadata": {},
   "source": [
    "5. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d09a4eb9-77c7-4b36-b0a1-1fd975e124fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.09258532757944292\n",
      "Confusion Matrix:\n",
      " [[15398   497]\n",
      " [ 1816   118]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93     15895\n",
      "           1       0.19      0.06      0.09      1934\n",
      "\n",
      "    accuracy                           0.87     17829\n",
      "   macro avg       0.54      0.51      0.51     17829\n",
      "weighted avg       0.82      0.87      0.84     17829\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare features (sentiment scores) and labels (offender or not)\n",
    "X = input_data[['sentiment_score']].values  # Features: sentiment score\n",
    "y = input_data['label'].values  # Labels: offender (1) or non-offender (0)\n",
    "\n",
    "# Split the dataset into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance using F1 score, confusion matrix, and classification report\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Confusion Matrix to evaluate true positives, false positives, etc.\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Detailed Classification Report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e73309-da80-44ab-a094-7e6725b55de1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d51d58e-0caa-463a-9304-887b0daabbb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea865eb-802b-49d5-a652-6b0e836fe1af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e9b02e-6e69-4bf0-93b3-3302850fa846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb5e9cb-b8e8-482e-b765-1a6ceec96fba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0306a5-44b4-4003-a1d6-c631cff63c96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
